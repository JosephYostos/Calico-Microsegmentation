# Module 3: Joining EKS cluster to Calico Cloud

**Goal:** Join EKS cluster to Calico Cloud management plane.

>In order to complete this module, you must have [Calico Cloud trial account](https://www.tigera.io/tigera-products/calico-cloud/).

## Steps

1. Join EKS cluster to Calico Cloud management plane.

    Use Calico Cloud install script provided in the welcome email for Calico Cloud trial account.

    ```bash
    # script should look similar to this
    curl https://installer.calicocloud.io/xxxxxx_yyyyyyy-saay-management_install.sh | bash
    ```

    Joining the cluster to Calico Cloud can take a few minutes. Wait for the installation script to finish before you proceed to the next step.

2. Configure log aggregation and flush intervals.

    ```bash
    kubectl patch felixconfiguration.p default -p '{"spec":{"flowLogsFlushInterval":"10s"}}'
    kubectl patch felixconfiguration.p default -p '{"spec":{"dnsLogsFlushInterval":"10s"}}'
    kubectl patch felixconfiguration.p default -p '{"spec":{"flowLogsFileAggregationKindForAllowed":1}}'
    ```

3. Configure Felix for log data collection.

    ```bash
    kubectl patch felixconfiguration default --type='merge' -p '{"spec":{"policySyncPathPrefix":"/var/run/nodeagent","l7LogsFileEnabled":true}}'
    ```

4. Configure Calico `LogCollector` to get EKS audit logs from `CloudWatch` service.

    Calico compliance reports require audit logs generated by Kubernetes API server in order to include all necessary audit records in the reports. EKS cluster uses `CloudWatch` service to collect audit logs from the Kubernetes API server. For the instructions to configure Calico `LogCollector` with EKS values refer to the [official documentation](https://docs.tigera.io/compliance/compliance-reports/compliance-managed-cloud#enable-audit-logs-in-eks).

    >You can view EKS logs in the [CloudWatch console](https://console.aws.amazon.com/cloudwatch/home#logs:prefix=/aws/eks).

    a. Configure IAM user to read logs from the `CloudWatch` service.

    ```bash
    # configure IAM user to allow
    IAM_USER='tigera-workshop-cloudwatch-reader'
    # create IAM user
    aws iam create-user --user-name $IAM_USER
    # give user programmatic access by creating access key
    USER_ACCESS_KEY=$(aws iam create-access-key --user-name $IAM_USER)
    # expose access key info via vars
    ACCESS_KEY_ID=$(echo $USER_ACCESS_KEY | jq .AccessKey.AccessKeyId | sed -e 's/^"//' -e 's/"$//')
    ACCESS_KEY_SECRET=$(echo $USER_ACCESS_KEY | jq .AccessKey.SecretAccessKey | sed -e 's/^"//' -e 's/"$//')

    # get CloudWatch read-only policy arn
    CLOUDWATCH_POLICY_ARN=$(aws iam list-policies --query 'Policies[?PolicyName==`CloudWatchLogsReadOnlyAccess`].Arn' --output text)
    # attach CloudWatch read-only policy to the user
    aws iam attach-user-policy --user-name $IAM_USER --policy-arn $CLOUDWATCH_POLICY_ARN
    # tag the user
    aws iam tag-user --user-name $IAM_USER --tags '{"Key": "purpose", "Value": "tigera-eks-workshop"}'
    ```

    b. Configure `LogCollector` to pull EKS audit logs.

    The `CloudWatch` resource group name for EKS cluster follows this format: `/aws/eks/<cluster-name>/cluster`.

    ```bash
    # verify that the EKS cluster has logging enabled and contains 'audit' log type
    eksctl get cluster tigera-workshop -ojson | jq .[].Logging

    # set CloudWatch resource name
    CLUSTER_NAME='tigera-workshop'
    CLOUDWATCH_GROUP_NAME="/aws/eks/$CLUSTER_NAME/cluster"
    AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')
    LOG_STREAM_PREFIX='kube-apiserver-audit-'
    # configure LogCollector resource with EKS values
    kubectl patch logcollector tigera-secure --type merge -p "{\"spec\":{\"additionalSources\":{\"eksCloudwatchLog\":{\"fetchInterval\":60,\"groupName\":\"$CLOUDWATCH_GROUP_NAME\",\"region\":\"$AWS_REGION\",\"streamPrefix\":\"$LOG_STREAM_PREFIX\"}}}}"
    ```

    c. Configure authentication between Calico and CloudWatch service.

    Create secret with IAM user credentials.

    ```bash
    cat > configs/cloudwatch-auth.yaml << EOF
    apiVersion: v1
    kind: Secret
    metadata:
      name: tigera-eks-log-forwarder-secret
      namespace: tigera-operator
    type: Opaque
    data:
      aws-id: $(echo -n $ACCESS_KEY_ID | base64 -w0)
      aws-key: $(echo -n $ACCESS_KEY_SECRET | base64 -w0)
    EOF
    ```

    Deploy secret to the cluster.

    ```bash
    kubectl apply -f configs/cloudwatch-auth.yaml
    ```

[Next -> Module 4](../modules/configuring-demo-apps.md)
